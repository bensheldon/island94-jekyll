---
layout: post
title: Taking responsibility for safety on the line
date: 2017-12-03 21:08 -0800
---

From Sidney Dekker's _The Field Guide to Understanding 'Human Error'_:

> To take responsibility for safety on the line, you should first and foremost look at people's work, more than (just) at people's safety.

> - What does it take to get the job done on a daily basis? What are the "workarounds," innovations or improvisations that people have to engage in in order to meet the various demands imposed on them?
> - What are the daily "frustrations" that people encounter in getting a piece of machinery, or technology, or even a team of people (for example, contractors), to work the way they expect?
> - What do your people believe is "dodgy" about the operation? Ask them that question directly, and you may get some surprising results.
> - What do your people have to do to "finish the design" of the tools and technologies that the organization has given them to work with? Finishing the design may be obvious from little post-it notes with reminders for particular switches or settings, or more "advanced" jury-rigged solutions (like an upside-down paper coffee cup on the flap handle of the 60-million dollar jet I flew, so as to not forget to set the flaps under certain circumstances). Such finishing the design can be a marker of resilience: people adapt their tools and technologies to forestall or contain the risks they know about. But it can also be a pointer to places where your system may be more brittle than you think.
> - How often do your people have to say to each other: "here's how to make it work" when they discuss a particular technology or portion of your operation? What is the informal teaching and "coaching" that is going on in order to make that happen?

And on goal conflict:

> Production pressure and goal conflicts are the essence of most operational systems. Though safety is a (stated) priority, these systems do not exist to be safe. They exist to provide a service or product, to achieve economic gain, to maximize capacity utilization. But still they have to be safe. One starting point, then, for understanding a driver behind routine deviations, is to look deeper into these goal interactions, these basic incompatibilities in what people need to strive for in their work. If you want to understand 'human error,' you need to find out how people themselves view these conflicts from inside their operational reality, and how this contrasts with other views of the same activities (for example, management, regulator, public).
